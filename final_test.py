# -*- coding: utf-8 -*-
"""FINAL_test.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Lq_CFQ3WWrg35jtVZ33HMp8OLq7Q1CA9
"""

from google.colab import drive
drive.mount('/content/drive')

# ===== BLOCK 0: Setup & Config =====

import os, io, json, random, math, time, warnings
from pathlib import Path
import numpy as np
import pandas as pd
from PIL import Image, ImageOps, ImageFilter
from tqdm.auto import tqdm

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
import torchvision
import torchvision.transforms as T
from torchvision.transforms import InterpolationMode
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

warnings.filterwarnings('ignore')

# Reproducibility
SEED = 42
random.seed(SEED); np.random.seed(SEED)
torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print("Device:", device)

# Paths / Config
RAW_ROOT = Path("/content/drive/MyDrive/GANAttributes")
OUT_ROOT = Path("/content/drive/MyDrive/model_data")
RUN_DIR  = OUT_ROOT / "runs"
OUT_ROOT.mkdir(parents=True, exist_ok=True); RUN_DIR.mkdir(parents=True, exist_ok=True)

# UPDATED: Now includes Real class for real vs fake detection
ALL_CLASSES = ["ProGAN", "StyleGAN2", "BigGAN", "RealPhotos"]
GAN_CLASSES = ["ProGAN", "StyleGAN2", "BigGAN"]  # For GAN attribution
REAL_FAKE_CLASSES = ["Real", "Fake"]  # For real vs fake detection

CLASS_TO_IDX = {c:i for i,c in enumerate(GAN_CLASSES)}  # Keep original for GAN attribution
REAL_FAKE_TO_IDX = {c:i for i,c in enumerate(REAL_FAKE_CLASSES)}

MAX_CAP = 4000
IMG_SIZE = 256

# Training - UNCHANGED for your working GAN attribution
NUM_EPOCHS = 10
BATCH_SIZE = 16
NUM_WORKERS = 6
LR_GC = 2e-4
LR_D  = 1e-4
WEIGHT_DECAY = 1e-5
PATIENCE = 6

# NEW: Real vs Fake detector training params
RF_NUM_EPOCHS = 12
RF_BATCH_SIZE = 32
RF_LR = 1e-4
RF_PATIENCE = 4

# Loss weights - UNCHANGED for your working GAN attribution
ALPHA_STAMP = 0.20
LAMBDA_ADV   = 0.5
LAMBDA_PERC  = 0.10
LAMBDA_RES   = 0.005
LAMBDA_HIPASS= 0.02
LAMBDA_CLS_R = 1.5
LAMBDA_CLS_S = 1.0

# Saving - UPDATED
CHECKPOINT = RUN_DIR / "best_gfd2_model.pt"
RF_CHECKPOINT = RUN_DIR / "best_real_fake_model.pt"  # NEW
METRICS_CSV= RUN_DIR / "metrics.csv"
RF_METRICS_CSV = RUN_DIR / "rf_metrics.csv"  # NEW
CURVES_PNG = RUN_DIR / "training_curves.png"
VAL_CM_PNG = RUN_DIR / "cm_val.png"
TEST_CM_PNG= RUN_DIR / "cm_test.png"
RF_VAL_CM_PNG = RUN_DIR / "rf_cm_val.png"  # NEW
RF_TEST_CM_PNG = RUN_DIR / "rf_cm_test.png"  # NEW
VAL_REPORT = RUN_DIR / "val_report.txt"
TEST_REPORT= RUN_DIR / "test_report.txt"
RF_VAL_REPORT = RUN_DIR / "rf_val_report.txt"  # NEW
RF_TEST_REPORT = RUN_DIR / "rf_test_report.txt"  # NEW
META_JSON  = RUN_DIR / "run_metadata.json"
LABEL_MAP  = RUN_DIR / "label_map.json"

# Save label mappings
json.dump({
    "gan_classes": GAN_CLASSES,
    "gan_class_to_idx": CLASS_TO_IDX,
    "real_fake_classes": REAL_FAKE_CLASSES,
    "real_fake_to_idx": REAL_FAKE_TO_IDX
}, open(LABEL_MAP, "w"))

print("GAN Classes:", GAN_CLASSES)
print("Real/Fake Classes:", REAL_FAKE_CLASSES)
print("Output:", OUT_ROOT)

# ===== BLOCK 1: Data Collection & Preparation =====

def collect_all_data(root, all_classes):
    """Collect data for both real vs fake and GAN attribution"""
    exts = {".png",".jpg",".jpeg",".bmp",".webp",".PNG",".JPG",".JPEG",".BMP",".WEBP"}

    # Collect all data with original labels
    rows_all = []
    rows_gan_only = []
    rows_real_fake = []

    for cls in all_classes:
        folder = root / cls
        assert folder.exists(), f"Missing folder: {folder}"
        files = [p for p in folder.iterdir() if p.suffix in exts]
        print(f"{cls}: {len(files)} images")

        for p in files:
            # Original data for GAN attribution (excluding RealPhotos)
            if cls in GAN_CLASSES:
                rows_gan_only.append({"path": str(p), "label": cls})

            # Real vs Fake data
            real_fake_label = "Real" if cls == "RealPhotos" else "Fake"
            rows_real_fake.append({"path": str(p), "label": real_fake_label, "original_label": cls})

            # All data
            rows_all.append({"path": str(p), "label": cls})

    df_all = pd.DataFrame(rows_all)
    df_gan_only = pd.DataFrame(rows_gan_only)
    df_real_fake = pd.DataFrame(rows_real_fake)

    return df_all, df_gan_only, df_real_fake

df_all, df_gan_only, df_real_fake = collect_all_data(RAW_ROOT, ALL_CLASSES)

# Save raw data
df_all.to_csv(OUT_ROOT / "all_files.csv", index=False)
df_gan_only.to_csv(OUT_ROOT / "gan_only_files.csv", index=False)
df_real_fake.to_csv(OUT_ROOT / "real_fake_files.csv", index=False)

print("\nData distribution:")
print("GAN only:", df_gan_only['label'].value_counts())
print("Real vs Fake:", df_real_fake['label'].value_counts())

# ===== BLOCK 2: Data Balancing & Splitting =====

def balance_and_split(df, classes, class_to_idx_map, max_cap, seed=SEED):
    """Balance data and create train/val/test splits"""
    # Balance
    dfs = []
    for cls in classes:
        sub = df[df['label']==cls]
        take = min(len(sub), max_cap)
        dfs.append(sub.sample(n=take, random_state=seed))

    df_balanced = pd.concat(dfs, ignore_index=True).sample(frac=1.0, random_state=seed).reset_index(drop=True)

    # Stratified split
    X = df_balanced.index.values
    y = df_balanced['label'].values

    sss1 = StratifiedShuffleSplit(n_splits=1, test_size=0.30, random_state=seed)
    train_idx, temp_idx = next(sss1.split(X, y))

    sss2 = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=seed)
    val_rel, test_rel = next(sss2.split(temp_idx, y[temp_idx]))
    val_idx, test_idx = temp_idx[val_rel], temp_idx[test_rel]

    df_balanced['split'] = ''
    df_balanced.loc[train_idx, 'split'] = 'train'
    df_balanced.loc[val_idx, 'split'] = 'val'
    df_balanced.loc[test_idx, 'split'] = 'test'

    return df_balanced

# Balance and split GAN attribution data (UNCHANGED)
df_gan_balanced = balance_and_split(df_gan_only, GAN_CLASSES, CLASS_TO_IDX, MAX_CAP)
df_gan_balanced.to_csv(OUT_ROOT / "manifest_gan.csv", index=False)

print("\nGAN Attribution - Balanced distribution:")
print(df_gan_balanced.groupby(['split','label']).size().unstack(fill_value=0))

# Balance and split Real vs Fake data (NEW)
df_rf_balanced = balance_and_split(df_real_fake, REAL_FAKE_CLASSES, REAL_FAKE_TO_IDX, MAX_CAP)
df_rf_balanced.to_csv(OUT_ROOT / "manifest_real_fake.csv", index=False)

print("\nReal vs Fake - Balanced distribution:")
print(df_rf_balanced.groupby(['split','label']).size().unstack(fill_value=0))

# ===== BLOCK 3: Dataset Classes (UPDATED) =====

class RandomDegrade:
    """Artifact-preserving: JPEG recompress + tiny rescale with mixed kernels + mild blur/sharpen."""
    def __init__(self, apply_prob=1.0):
        self.apply_prob = apply_prob
        self.kernels = [Image.NEAREST, Image.BILINEAR, Image.BICUBIC, Image.BOX, Image.LANCZOS]

    def _jpeg(self, img):
        q = random.randint(50, 100)
        buf = io.BytesIO()
        img.save(buf, format='JPEG', quality=q, optimize=True)
        buf.seek(0)
        return Image.open(buf).convert('RGB')

    def _tiny_rescale(self, img):
        s = random.uniform(0.9, 1.1)
        w, h = img.size
        tw, th = max(8, int(w*s)), max(8, int(h*s))
        img = img.resize((tw, th), resample=random.choice(self.kernels))
        return img.resize((w, h), resample=random.choice(self.kernels))

    def _blur_or_sharpen(self, img):
        if random.random() < 0.5:
            return img.filter(ImageFilter.GaussianBlur(radius=random.uniform(0.1,0.8)))
        else:
            return img.filter(ImageFilter.UnsharpMask(radius=1, percent=80, threshold=3))

    def __call__(self, img):
        if random.random() > self.apply_prob:
            return img
        img = self._jpeg(img)
        img = self._tiny_rescale(img)
        img = self._blur_or_sharpen(img)
        return img

class CarrierBuilder:
    """Build a carrier (content) by heavy blur + down-up to suppress existing fingerprints."""
    def __init__(self):
        self.kernels = [Image.BILINEAR, Image.BICUBIC, Image.BOX, Image.LANCZOS]
    def __call__(self, img):
        img = img.filter(ImageFilter.GaussianBlur(radius=random.uniform(1.0,2.2)))
        w,h = img.size
        s = random.uniform(0.5, 0.85)
        tw, th = max(8,int(w*s)), max(8,int(h*s))
        img = img.resize((tw, th), resample=random.choice(self.kernels))
        img = img.resize((w, h),  resample=random.choice(self.kernels))
        return img

def resize_crop_256(img: Image.Image):
    s = random.uniform(0.95, 1.05)
    w,h = img.size
    img = img.resize((max(8,int(w*s)), max(8,int(h*s))), resample=Image.BICUBIC)
    w,h = img.size
    if w < IMG_SIZE or h < IMG_SIZE:
        pad_w = max(0, IMG_SIZE - w); pad_h = max(0, IMG_SIZE - h)
        img = ImageOps.expand(img, border=(pad_w//2, pad_h//2, pad_w - pad_w//2, pad_h - pad_h//2), fill=0)
    w,h = img.size
    left = max(0,(w-IMG_SIZE)//2); top = max(0,(h-IMG_SIZE)//2)
    img = img.crop((left, top, left+IMG_SIZE, top+IMG_SIZE))
    return img

IMAGENET_NORM = T.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])

# UNCHANGED: GAN Attribution Dataset (your working code)
class GFDTwoViewDataset(Dataset):
    def __init__(self, df, split, train=True):
        self.df = df[df['split']==split].reset_index(drop=True)
        self.paths = self.df['path'].tolist()
        self.labels= [CLASS_TO_IDX[l] for l in self.df['label']]
        self.num_classes = len(GAN_CLASSES)

        self.class_to_indices = {k: [] for k in range(self.num_classes)}
        for i, lab in enumerate(self.labels):
            self.class_to_indices[lab].append(i)

        self.train = train
        self.degrade = RandomDegrade(apply_prob=1.0 if train else 0.0)
        self.carrier = CarrierBuilder()
        self.to_tensor = T.ToTensor()

    def __len__(self):
        return len(self.paths)

    def _load_img(self, path):
        with Image.open(path) as img:
            img = ImageOps.exif_transpose(img).convert('RGB')
            return img

    def __getitem__(self, idx):
        path_x = self.paths[idx]
        y      = self.labels[idx]

        x = self._load_img(path_x)
        x = resize_crop_256(x)
        if self.train:
            x = self.degrade(x)

        other_classes = [k for k in range(self.num_classes) if k != y]
        oc = random.choice(other_classes)
        j = random.choice(self.class_to_indices[oc])
        c = self._load_img(self.paths[j])
        c = resize_crop_256(c)
        c = self.carrier(c)

        x_t = IMAGENET_NORM(self.to_tensor(x))
        c_t = IMAGENET_NORM(self.to_tensor(c))
        return x_t, c_t, y

# NEW: Real vs Fake Dataset
class RealFakeDataset(Dataset):
    def __init__(self, df, split, train=True):
        self.df = df[df['split']==split].reset_index(drop=True)
        self.paths = self.df['path'].tolist()
        self.labels = [REAL_FAKE_TO_IDX[l] for l in self.df['label']]

        self.train = train
        self.degrade = RandomDegrade(apply_prob=0.7 if train else 0.0)  # Lighter augmentation
        self.to_tensor = T.ToTensor()

    def __len__(self):
        return len(self.paths)

    def _load_img(self, path):
        with Image.open(path) as img:
            img = ImageOps.exif_transpose(img).convert('RGB')
            return img

    def __getitem__(self, idx):
        path = self.paths[idx]
        y = self.labels[idx]

        img = self._load_img(path)
        img = resize_crop_256(img)


        if self.train:
            img = self.degrade(img)

        img_t = IMAGENET_NORM(self.to_tensor(img))
        return img_t, y

# ===== BLOCK 4: Models (UPDATED) =====
from torchvision.models import efficientnet_b3, EfficientNet_B3_Weights, vgg16, VGG16_Weights, resnet50, ResNet50_Weights


# UNCHANGED: Your working GAN attribution models
class UNetRes(nn.Module):
    def __init__(self, in_ch=3, base=32, scale=ALPHA_STAMP):
        super().__init__()
        self.scale = scale
        def C(in_c, out_c, k=3, s=1, p=1): return nn.Sequential(
            nn.Conv2d(in_c, out_c, k, s, p), nn.BatchNorm2d(out_c), nn.ReLU(inplace=True))
        self.enc1 = nn.Sequential(C(in_ch, base), C(base, base))
        self.enc2 = nn.Sequential(C(base, base*2, s=2), C(base*2, base*2))
        self.enc3 = nn.Sequential(C(base*2, base*4, s=2), C(base*4, base*4))
        self.enc4 = nn.Sequential(C(base*4, base*8, s=2), C(base*8, base*8))

        self.dec3 = nn.Sequential(C(base*8+base*4, base*4), C(base*4, base*4))
        self.dec2 = nn.Sequential(C(base*4+base*2, base*2), C(base*2, base*2))
        self.dec1 = nn.Sequential(C(base*2+base, base), C(base, base))
        self.outc = nn.Conv2d(base, 3, 1)

        self.pool = nn.MaxPool2d(2)

    def forward(self, x):
        e1 = self.enc1(x)
        e2 = self.enc2(e1)
        e3 = self.enc3(e2)
        e4 = self.enc4(e3)

        d3 = F.interpolate(e4, scale_factor=2, mode='bilinear', align_corners=False)
        d3 = self.dec3(torch.cat([d3, e3], dim=1))
        d2 = F.interpolate(d3, scale_factor=2, mode='bilinear', align_corners=False)
        d2 = self.dec2(torch.cat([d2, e2], dim=1))
        d1 = F.interpolate(d2, scale_factor=2, mode='bilinear', align_corners=False)
        d1 = self.dec1(torch.cat([d1, e1], dim=1))
        r  = torch.tanh(self.outc(d1)) * self.scale
        return r

class EncoderClassifier(nn.Module):
    def __init__(self, num_classes=3):
        super().__init__()
        weights = EfficientNet_B3_Weights.IMAGENET1K_V1
        self.backbone = efficientnet_b3(weights=weights)
        feat_dim = self.backbone.classifier[1].in_features
        self.backbone.classifier = nn.Identity()
        self.head = nn.Sequential(
            nn.Dropout(0.4),
            nn.Linear(feat_dim, 256),
            nn.ReLU(inplace=True),
            nn.Dropout(0.2),
            nn.Linear(256, num_classes)
        )
    def forward(self, x):
        feat = self.backbone(x)
        return self.head(feat)

def conv_block(in_c, out_c, k=4, s=2, p=1, bn=True):
    layers = [nn.Conv2d(in_c, out_c, k, s, p)]
    if bn: layers += [nn.BatchNorm2d(out_c)]
    layers += [nn.LeakyReLU(0.2, inplace=True)]
    return nn.Sequential(*layers)

class PatchDiscriminator(nn.Module):
    def __init__(self, in_ch=3):
        super().__init__()
        self.net = nn.Sequential(
            conv_block(in_ch, 64, bn=False),
            conv_block(64, 128),
            conv_block(128, 256),
            conv_block(256, 512, s=1),
            nn.Conv2d(512, 1, 4, 1, 1)
        )
    def forward(self, x): return self.net(x)

class VGGPerceptual(nn.Module):
    def __init__(self):
        super().__init__()
        vgg = vgg16(weights=VGG16_Weights.IMAGENET1K_FEATURES).features.eval()
        self.slice = nn.Sequential(*list(vgg.children())[:9])
        for p in self.slice.parameters():
            p.requires_grad = False

    def forward(self, x_norm, y_norm):
        fx = self.slice(x_norm)
        fy = self.slice(y_norm)
        return F.l1_loss(fx, fy)

# NEW: Real vs Fake Classifier
class RealFakeClassifier(nn.Module):
    def __init__(self, num_classes=2):
        super().__init__()
        weights = ResNet50_Weights.IMAGENET1K_V2
        self.backbone = resnet50(weights=weights)
        feat_dim = self.backbone.fc.in_features
        self.backbone.fc = nn.Identity()

        self.classifier = nn.Sequential(
            nn.Dropout(0.5),
            nn.Linear(feat_dim, 512),
            nn.ReLU(inplace=True),
            nn.Dropout(0.3),
            nn.Linear(512, 128),
            nn.ReLU(inplace=True),
            nn.Dropout(0.2),
            nn.Linear(128, num_classes)
        )

    def forward(self, x):
        feat = self.backbone(x)
        return self.classifier(feat)

# Initialize models
G = UNetRes(scale=ALPHA_STAMP).to(device)
C = EncoderClassifier(num_classes=len(GAN_CLASSES)).to(device)
D = PatchDiscriminator().to(device)
perc_net = VGGPerceptual().to(device).eval()


RF_model = RealFakeClassifier(num_classes=len(REAL_FAKE_CLASSES)).to(device)


print("Models initialized:")
print(f"- Generator (G): {sum(p.numel() for p in G.parameters()):,} parameters")
print(f"- GAN Classifier (C): {sum(p.numel() for p in C.parameters()):,} parameters")
print(f"- Discriminator (D): {sum(p.numel() for p in D.parameters()):,} parameters")
print(f"- Real/Fake Classifier (RF): {sum(p.numel() for p in RF_model.parameters()):,} parameters")

bce_logits = nn.BCEWithLogitsLoss()
ce_loss = nn.CrossEntropyLoss()

# ===== BLOCK 5: Training Real vs Fake Classifier (NEW) =====


print("\n" + "="*60)
print("üöÄ PHASE 1: Training Real vs Fake Classifier")
print("="*60)


# Create Real vs Fake data loaders
rf_train_ds = RealFakeDataset(df_rf_balanced, 'train', train=True)
rf_val_ds = RealFakeDataset(df_rf_balanced, 'val', train=False)
rf_test_ds = RealFakeDataset(df_rf_balanced, 'test', train=False)

rf_train_loader = DataLoader(rf_train_ds, batch_size=RF_BATCH_SIZE, shuffle=True,
                            num_workers=NUM_WORKERS, pin_memory=True, drop_last=True)

rf_val_loader = DataLoader(rf_val_ds, batch_size=RF_BATCH_SIZE*2, shuffle=False,
                          num_workers=NUM_WORKERS, pin_memory=True)
rf_test_loader = DataLoader(rf_test_ds, batch_size=RF_BATCH_SIZE*2, shuffle=False,
                           num_workers=NUM_WORKERS, pin_memory=True)

print(f"Real vs Fake Batches ‚Üí Train: {len(rf_train_loader)} | Val: {len(rf_val_loader)} | Test: {len(rf_test_loader)}")


# Training setup
rf_optimizer = torch.optim.AdamW(RF_model.parameters(), lr=RF_LR, weight_decay=WEIGHT_DECAY)
rf_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(rf_optimizer, T_max=RF_NUM_EPOCHS)
rf_scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())

# Training loop
rf_history = {"epoch":[], "train_loss":[], "val_acc":[], "lr":[]}
rf_best_val_acc, rf_best_epoch = 0.0, -1
rf_epochs_no_improve = 0
rf_start = time.time()

@torch.no_grad()
def eval_real_fake_classifier(model, loader):
    model.eval()
    all_preds, all_true = [], []
    total_loss = 0

    for x, y in tqdm(loader, desc="Eval RF", leave=False):
        x, y = x.to(device), y.to(device)
        logits = model(x)
        loss = ce_loss(logits, y)
        total_loss += loss.item()

        preds = logits.argmax(1)
        all_preds.extend(preds.cpu().tolist())
        all_true.extend(y.cpu().tolist())

    acc = (np.array(all_preds) == np.array(all_true)).mean() * 100.0
    avg_loss = total_loss / len(loader)
    cm = confusion_matrix(all_true, all_preds, labels=list(range(len(REAL_FAKE_CLASSES))))
    rpt = classification_report(all_true, all_preds, target_names=REAL_FAKE_CLASSES, digits=4)

    return acc, avg_loss, cm, rpt

for epoch in range(1, RF_NUM_EPOCHS + 1):
    RF_model.train()
    run_loss = 0.0
    pbar = tqdm(rf_train_loader, desc=f"RF Train {epoch}/{RF_NUM_EPOCHS}", leave=False)

    for x, y in pbar:
        x, y = x.to(device), y.to(device)

        rf_optimizer.zero_grad(set_to_none=True)

        with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):
            logits = RF_model(x)
            loss = ce_loss(logits, y)

        rf_scaler.scale(loss).backward()
        torch.nn.utils.clip_grad_norm_(RF_model.parameters(), 1.0)
        rf_scaler.step(rf_optimizer)
        rf_scaler.update()

        run_loss += loss.item()
        pbar.set_postfix(loss=f"{run_loss/(pbar.n+1e-8):.4f}")

    rf_scheduler.step()

    # Validation
    val_acc, val_loss, _, _ = eval_real_fake_classifier(RF_model, rf_val_loader)

    rf_history["epoch"].append(epoch)
    rf_history["train_loss"].append(run_loss/len(rf_train_loader))
    rf_history["val_acc"].append(val_acc)
    rf_history["lr"].append(rf_scheduler.get_last_lr()[0])

    print(f"üìÖ RF Epoch {epoch}/{RF_NUM_EPOCHS} | TrainLoss {rf_history['train_loss'][-1]:.4f} | "
          f"ValAcc {val_acc:.2f}% | lr {rf_history['lr'][-1]:.6f}")

    if val_acc > rf_best_val_acc:
        rf_best_val_acc, rf_best_epoch = val_acc, epoch
        rf_epochs_no_improve = 0
        torch.save({
            "epoch": epoch,
            "model": RF_model.state_dict(),
            "optimizer": rf_optimizer.state_dict(),
            "val_acc": val_acc,
            "classes": REAL_FAKE_CLASSES
        }, RF_CHECKPOINT)
        print(f"üéØ New best RF val acc: {val_acc:.2f}% ‚úÖ Saved")
    else:
        rf_epochs_no_improve += 1

    if rf_epochs_no_improve >= RF_PATIENCE:
        print("üõë RF Early stopping.")
        break

rf_elapsed = (time.time() - rf_start) / 60
print(f"‚è±Ô∏è Real vs Fake training finished in {rf_elapsed:.1f} min | Best ValAcc {rf_best_val_acc:.2f}% @ epoch {rf_best_epoch}")

# Load best RF model
rf_ckpt = torch.load(RF_CHECKPOINT, map_location=device, weights_only=False)
RF_model.load_state_dict(rf_ckpt["model"])
print(f"üì• Loaded best RF checkpoint")

# Evaluate RF model
rf_val_acc, _, rf_cm_val, rf_rpt_val = eval_real_fake_classifier(RF_model, rf_val_loader)
rf_test_acc, _, rf_cm_test, rf_rpt_test = eval_real_fake_classifier(RF_model, rf_test_loader)

def plot_cm(cm, title, path, classes):
    plt.figure(figsize=(5,4))
    sns.heatmap(cm, annot=True, fmt="d", xticklabels=classes, yticklabels=classes)
    plt.xlabel("Predicted"); plt.ylabel("True"); plt.title(title)
    plt.tight_layout(); plt.savefig(path, dpi=180); plt.close()

# Save RF results
plot_cm(rf_cm_val, f"RF Val Confusion (Acc={rf_val_acc:.2f}%)", RF_VAL_CM_PNG, REAL_FAKE_CLASSES)
plot_cm(rf_cm_test, f"RF Test Confusion (Acc={rf_test_acc:.2f}%)", RF_TEST_CM_PNG, REAL_FAKE_CLASSES)
with open(RF_VAL_REPORT, "w") as f: f.write(rf_rpt_val)
with open(RF_TEST_REPORT, "w") as f: f.write(rf_rpt_test)

pd.DataFrame(rf_history).to_csv(RF_METRICS_CSV, index=False)

print(f"üß™ RF Val acc: {rf_val_acc:.2f}% | Test acc: {rf_test_acc:.2f}%")

# ===== BLOCK 6: Training GAN Attribution (UNCHANGED - Your Working Code) =====

print("\n" + "="*60)
print("üöÄ PHASE 2: Training GAN Attribution (Your Working Model)")
print("="*60)

# Create GAN attribution data loaders (UNCHANGED)
train_ds = GFDTwoViewDataset(df_gan_balanced, 'train', train=True)
val_ds = GFDTwoViewDataset(df_gan_balanced, 'val', train=False)
test_ds = GFDTwoViewDataset(df_gan_balanced, 'test', train=False)

train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,
                          num_workers=NUM_WORKERS, pin_memory=True, drop_last=True)
val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE*2, shuffle=False,
                        num_workers=NUM_WORKERS, pin_memory=True)
test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE*2, shuffle=False,
                         num_workers=NUM_WORKERS, pin_memory=True)

print(f"GAN Attribution Batches ‚Üí Train: {len(train_loader)} | Val: {len(val_loader)} | Test: {len(test_loader)}")

# ===== BLOCK 7: GAN Training Utils (UNCHANGED) =====

@torch.no_grad()
def clamp_img(x):
    return torch.clamp(x, -3.0, 3.0)

def blur_lowpass(x):
    k = torch.tensor([[1,2,1],[2,4,2],[1,2,1]], dtype=torch.float32, device=x.device)
    k = k / k.sum()
    k = k.view(1,1,3,3)
    k = k.repeat(x.size(1),1,1,1)
    return F.conv2d(x, k, padding=1, groups=x.size(1))

def compose_stamp(carrier_norm, residual):
    x_hat = carrier_norm + residual
    return clamp_img(x_hat)

@torch.no_grad()
def eval_residual_only(model_G, model_C, loader):
    model_G.eval(); model_C.eval()
    all_preds, all_true = [], []
    for x, _, y in tqdm(loader, desc="Eval(residual)", leave=False):
        x, y = x.to(device), y.to(device)
        r = model_G(x)
        r_img = (r / (ALPHA_STAMP+1e-8) * 0.5 + 0.5)
        r_img = IMAGENET_NORM(r_img)
        logits = model_C(r_img)
        preds = logits.argmax(1)
        all_preds.extend(preds.detach().cpu().tolist())
        all_true.extend(y.detach().cpu().tolist())
    all_preds = np.array(all_preds); all_true = np.array(all_true)
    acc = (all_preds==all_true).mean()*100.0
    cm = confusion_matrix(all_true, all_preds, labels=list(range(len(GAN_CLASSES))))
    rpt = classification_report(all_true, all_preds, target_names=GAN_CLASSES, digits=4)
    return acc, cm, rpt

# ===== BLOCK 8: GAN Attribution Training (UNCHANGED) =====
optimizer_GC = torch.optim.AdamW(list(G.parameters()) + list(C.parameters()),
                                 lr=LR_GC, weight_decay=WEIGHT_DECAY)
optimizer_D = torch.optim.AdamW(D.parameters(), lr=LR_D, weight_decay=0.0)
sched_GC = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_GC, T_max=NUM_EPOCHS)
sched_D = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_D, T_max=NUM_EPOCHS)
scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())

history = {"epoch":[], "train_loss":[], "val_acc":[], "lr_GC":[], "lr_D":[]}
best_val_acc, best_epoch = 0.0, -1
epochs_no_improve = 0
start = time.time()

print("üöÄ Training GAN Attribution on:", device)
for epoch in range(1, NUM_EPOCHS+1):
    is_warmup = (epoch <= 2)
    G.train(); C.train(); D.train()
    run_loss = 0.0
    pbar = tqdm(train_loader, desc=f"GAN Train {epoch}/{NUM_EPOCHS}", leave=False)
    for x, c, y in pbar:
        x, c, y = x.to(device), c.to(device), y.to(device)

        with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):
            r = G(x)
            r_img = (r / (ALPHA_STAMP+1e-8) * 0.5 + 0.5)
            r_img = IMAGENET_NORM(r_img)
            c_hat = compose_stamp(c, r)

        optimizer_D.zero_grad(set_to_none=True)
        with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):
            if not is_warmup:
                d_real = D(c)
                d_fake = D(c_hat.detach())
                real_t = torch.ones_like(d_real)
                fake_t = torch.zeros_like(d_fake)
                loss_D = 0.5*(bce_logits(d_real, real_t) + bce_logits(d_fake, fake_t))
            else:
                loss_D = torch.tensor(0.0, device=device)

        if not is_warmup:
            scaler.scale(loss_D).backward()
            scaler.step(optimizer_D)

        optimizer_GC.zero_grad(set_to_none=True)
        with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):
            logits_r = C(r_img)
            logits_hat = C(c_hat)
            loss_cls_r = ce_loss(logits_r, y) * LAMBDA_CLS_R
            loss_cls_s = ce_loss(logits_hat, y) * LAMBDA_CLS_S

            if not is_warmup:
                d_fake2 = D(c_hat)
                adv_t = torch.ones_like(d_fake2)
                loss_adv = bce_logits(d_fake2, adv_t) * LAMBDA_ADV
            else:
                loss_adv = torch.tensor(0.0, device=device)

            loss_perc = perc_net(c, c_hat) * LAMBDA_PERC
            loss_resmag = r.abs().mean() * LAMBDA_RES
            loss_hipass = blur_lowpass(r).abs().mean() * LAMBDA_HIPASS

            loss_GC = loss_cls_r + loss_cls_s + loss_adv + loss_perc + loss_resmag + loss_hipass

        scaler.scale(loss_GC).backward()
        torch.nn.utils.clip_grad_norm_(list(G.parameters()) + list(C.parameters()), 1.0)
        scaler.step(optimizer_GC)
        scaler.update()

        run_loss += (loss_D.item() + loss_GC.item())
        pbar.set_postfix(loss=f"{run_loss/(pbar.n+1e-8):.4f}")

    sched_GC.step(); sched_D.step()
    val_acc, _, _ = eval_residual_only(G, C, val_loader)

    history["epoch"].append(epoch)
    history["train_loss"].append(run_loss/len(train_loader))
    history["val_acc"].append(val_acc)
    history["lr_GC"].append(sched_GC.get_last_lr()[0])
    history["lr_D"].append(sched_D.get_last_lr()[0])

    print(f"üìÖ GAN Epoch {epoch}/{NUM_EPOCHS} | TrainLoss {history['train_loss'][-1]:.4f} | "
          f"ValAcc(residual) {val_acc:.2f}% | lrGC {history['lr_GC'][-1]:.6f} lrD {history['lr_D'][-1]:.6f}")
    print("   üîß Warm‚Äëup active (no D / no adv)") if is_warmup else None

    if val_acc > best_val_acc:
        best_val_acc, best_epoch = val_acc, epoch
        epochs_no_improve = 0
        torch.save({
            "epoch": epoch,
            "G": G.state_dict(),
            "C": C.state_dict(),
            "D": D.state_dict(),
            "opt_GC": optimizer_GC.state_dict(),
            "opt_D": optimizer_D.state_dict(),
            "val_acc": val_acc,
            "classes": GAN_CLASSES,
            "config": {
                "img_size": IMG_SIZE, "alpha_stamp": ALPHA_STAMP,
                "l_adv": LAMBDA_ADV, "l_perc": LAMBDA_PERC,
                "l_res": LAMBDA_RES, "l_hipass": LAMBDA_HIPASS
            }
        }, CHECKPOINT)
        print(f"üéØ New best GAN val acc (residual): {val_acc:.2f}% ‚úÖ Saved")
    else:
        epochs_no_improve += 1

    if epochs_no_improve >= PATIENCE:
        print("üõë GAN Early stopping.")
        break

elapsed = (time.time() - start)/60
print(f"‚è±Ô∏è GAN training finished in {elapsed:.1f} min | Best ValAcc(residual) {best_val_acc:.2f}% @ epoch {best_epoch}")

# Save GAN metrics & curves
pd.DataFrame(history).to_csv(METRICS_CSV, index=False)
plt.figure(figsize=(8,5))
plt.plot(history["epoch"], history["train_loss"], label="Train loss")
plt.plot(history["epoch"], history["val_acc"], label="Val acc (residual)")
plt.xlabel("Epoch"); plt.legend(); plt.tight_layout()
plt.savefig(CURVES_PNG, dpi=160); plt.close()

# Load best GAN model
ckpt = torch.load(CHECKPOINT, map_location=device, weights_only=False)
G.load_state_dict(ckpt["G"]); C.load_state_dict(ckpt["C"]); D.load_state_dict(ckpt["D"])
print(f"üì• Loaded best GAN checkpoint (epoch {ckpt['epoch']}, val_acc={ckpt['val_acc']:.2f}%)")

# ===== BLOCK 8: Load Best GAN Attribution Checkpoint (no retrain) =====
from pathlib import Path
import torch

CHECKPOINT = Path("/content/drive/MyDrive/model_data/runs/best_gfd2_model.pt")

assert CHECKPOINT.exists(), f"Checkpoint not found: {CHECKPOINT}"

ckpt = torch.load(CHECKPOINT, map_location=device, weights_only=False)

# If the checkpoint stores the class list, use it to keep mapping consistent
if "classes" in ckpt:
    GAN_CLASSES = ckpt["classes"]
    CLASS_TO_IDX = {c: i for i, c in enumerate(GAN_CLASSES)}
    print("‚úÖ Loaded GAN_CLASSES from checkpoint:", GAN_CLASSES)

# Make sure G, C, D are already instantiated exactly like in your training code (BLOCK 4).
# Then load the weights:
g_msg = G.load_state_dict(ckpt.get("G", {}), strict=False)
c_msg = C.load_state_dict(ckpt.get("C", {}), strict=False)
if "D" in ckpt and 'state_dict' not in ckpt["D"]:  # D might be optional for inference
    d_msg = D.load_state_dict(ckpt["D"], strict=False)
else:
    d_msg = None

G.to(device).eval()
C.to(device).eval()
D.to(device).eval()

print("üì• Loaded best GAN checkpoint.")
print(f"   Epoch: {ckpt.get('epoch', 'N/A')}, ValAcc: {ckpt.get('val_acc', 'N/A')}")
print("   G incompatible keys:", getattr(g_msg, "missing_keys", None), getattr(g_msg, "unexpected_keys", None))
print("   C incompatible keys:", getattr(c_msg, "missing_keys", None), getattr(c_msg, "unexpected_keys", None))
if d_msg is not None:
    print("   D incompatible keys:", getattr(d_msg, "missing_keys", None), getattr(d_msg, "unexpected_keys", None))
else:
    print("   D not present or not required for inference.")

# ===== BLOCK 9: GAN Attribution Evaluation (UNCHANGED) =====
val_acc, cm_val, rpt_val = eval_residual_only(G, C, val_loader)
test_acc, cm_test, rpt_test = eval_residual_only(G, C, test_loader)

plot_cm(cm_val, f"GAN Val Confusion (Acc={val_acc:.2f}%)", VAL_CM_PNG, GAN_CLASSES)
plot_cm(cm_test, f"GAN Test Confusion (Acc={test_acc:.2f}%)", TEST_CM_PNG, GAN_CLASSES)
with open(VAL_REPORT, "w") as f: f.write(rpt_val)
with open(TEST_REPORT, "w") as f: f.write(rpt_test)

print(f"üß™ GAN Val acc (residual): {val_acc:.2f}%")
print(f"üèÅ GAN Test acc (residual): {test_acc:.2f}%")

# ===== BLOCK 10: Integrated Inference Pipeline (NEW) =====

print("\n" + "="*60)
print("üîÆ INTEGRATED INFERENCE PIPELINE")
print("="*60)

to_tensor = T.ToTensor()

def preprocess_img_for_model(img: Image.Image):
    img = resize_crop_256(img)
    return IMAGENET_NORM(to_tensor(img))

@torch.no_grad()
def predict_real_fake(img_path: str, num_crops=5):
    """First stage: Real vs Fake detection"""
    RF_model.eval()
    with Image.open(img_path) as img_raw:
        img_raw = ImageOps.exif_transpose(img_raw).convert("RGB")
        logits_sum = torch.zeros(len(REAL_FAKE_CLASSES), device=device)

        for _ in range(num_crops):
            s = random.uniform(0.95, 1.05)
            w, h = img_raw.size
            img = img_raw.resize((max(8,int(w*s)), max(8,int(h*s))), resample=Image.BICUBIC)
            x = preprocess_img_for_model(img).unsqueeze(0).to(device)
            logits = RF_model(x).squeeze(0)
            logits_sum += logits

        probs = torch.softmax(logits_sum, dim=0).cpu().numpy()
        pred_idx = probs.argmax()
        pred_class = REAL_FAKE_CLASSES[pred_idx]
        confidence = float(probs[pred_idx])

        return pred_class, confidence

@torch.no_grad()
def predict_gan_attribution(img_path: str, num_crops=8):
    """Second stage: GAN attribution (only if fake)"""
    G.eval(); C.eval()
    with Image.open(img_path) as img_raw:
        img_raw = ImageOps.exif_transpose(img_raw).convert("RGB")
        logits_sum = torch.zeros(len(GAN_CLASSES), device=device)

        for _ in range(num_crops):
            s = random.uniform(0.95, 1.05)
            w, h = img_raw.size
            img = img_raw.resize((max(8,int(w*s)), max(8,int(h*s))), resample=Image.BICUBIC)
            img = resize_crop_256(img)
            x = IMAGENET_NORM(to_tensor(img)).unsqueeze(0).to(device)
            r = G(x)
            r_img = (r / (ALPHA_STAMP+1e-8) * 0.5 + 0.5)
            r_img = IMAGENET_NORM(r_img)
            logits = C(r_img).squeeze(0)
            logits_sum += logits

        probs = torch.softmax(logits_sum, dim=0).cpu().numpy()
        pred_idx = probs.argmax()
        pred_gan = GAN_CLASSES[pred_idx]
        confidence = float(probs[pred_idx])

        return pred_gan, confidence

def integrated_predict(img_path: str, rf_crops=5, gan_crops=8):
    """
    Integrated pipeline: Real vs Fake ‚Üí GAN Attribution
    Returns: (classification, gan_used, confidence)
    """
    try:
        # Stage 1: Real vs Fake
        rf_pred, rf_conf = predict_real_fake(img_path, num_crops=rf_crops)

        if rf_pred == "Real":
            return "Real", "N/A", rf_conf
        else:
            # Stage 2: GAN Attribution
            gan_pred, gan_conf = predict_gan_attribution(img_path, num_crops=gan_crops)
            # Use average confidence or minimum confidence for conservative estimate
            combined_conf = min(rf_conf, gan_conf)  # Conservative approach
            return "Fake", gan_pred, combined_conf

    except Exception as e:
        print(f"Error processing {img_path}: {e}")
        return "ERROR", "N/A", 0.0

# Test on a few examples
example_paths = [
    "/content/drive/MyDrive/myImages/BigGAN_00000.jpg",
    "/content/drive/MyDrive/myImages/progan_008.png",
    "/content/drive/MyDrive/myImages/real 00001.png",
    "/content/drive/MyDrive/myImages/styleGAN2_horse__001993.png",


    # Add more test images here
]

print("üîç Testing Integrated Pipeline:")
for path in example_paths:
    if Path(path).exists():
        classification, gan_used, confidence = integrated_predict(path)
        print(f"üì∏ {Path(path).name}: {classification} | GAN: {gan_used} | Conf: {confidence:.3f}")
    else:
        print(f"‚ö†Ô∏è File not found: {path}")

# ===== BLOCK 11: Bulk Inference with Integrated Pipeline (NEW) =====

print("\n" + "="*60)
print("üìä BULK INFERENCE - INTEGRATED PIPELINE")
print("="*60)

# CONFIG: set this to your folder with test images
INFER_ROOT = "/content/drive/MyDrive/myImages"  # CHANGE ME
OUT_CSV = "/content/drive/MyDrive/model_data/integrated_detection_results.csv"
RF_CROPS = 8     # crops for Real vs Fake detection
GAN_CROPS = 12   # crops for GAN attribution

# Gather images
import glob
exts = ("*.png", "*.jpg", "*.jpeg", "*.bmp", "*.webp", "*.tif", "*.tiff")
img_paths = []
for ext in exts:
    img_paths.extend(glob.glob(os.path.join(INFER_ROOT, "**", ext), recursive=True))
img_paths = sorted(set(img_paths))
print(f"Found {len(img_paths)} images under {INFER_ROOT}")

if len(img_paths) > 0:
    # Run integrated inference
    rows = []
    RF_model.eval(); G.eval(); C.eval()  # Ensure eval mode

    for p in tqdm(img_paths, desc="Integrated Detection"):
        classification, gan_used, confidence = integrated_predict(p, rf_crops=RF_CROPS, gan_crops=GAN_CROPS)
        rows.append({
            "image_name": os.path.basename(p),
            "image_path": p,
            "classification": classification,  # Real or Fake
            "gan_used": gan_used,             # N/A if Real, else GAN type
            "confidence": float(confidence)
        })

    # Save results
    df_results = pd.DataFrame(rows)
    df_results.to_csv(OUT_CSV, index=False)
    print(f"‚úÖ Saved {len(df_results)} results to: {OUT_CSV}")

    # Summary statistics
    print("\nüìà RESULTS SUMMARY:")
    print("Classification distribution:")
    print(df_results['classification'].value_counts())
    if 'Fake' in df_results['classification'].values:
        fake_subset = df_results[df_results['classification'] == 'Fake']
        print("\nGAN distribution (for fake images):")
        print(fake_subset['gan_used'].value_counts())

    print(f"\nAverage confidence: {df_results['confidence'].mean():.3f}")
    print(f"Confidence std: {df_results['confidence'].std():.3f}")

    # Show sample results
    display(df_results.head(10))
else:
    print(f"‚ö†Ô∏è No images found under {INFER_ROOT}")

# ===== BLOCK 12: Save Final Metadata =====

# Save comprehensive metadata
try:
    gan_metrics_df = pd.read_csv(METRICS_CSV)
    rf_metrics_df = pd.read_csv(RF_METRICS_CSV)
except:
    gan_metrics_df, rf_metrics_df = pd.DataFrame(), pd.DataFrame()

final_meta = {
    "pipeline_stages": {
        "stage1": "Real vs Fake Detection",
        "stage2": "GAN Attribution (if Fake)"
    },
    "stage1_real_fake": {
        "model": "ResNet50-based classifier",
        "classes": REAL_FAKE_CLASSES,
        "best_epoch": int(rf_ckpt["epoch"]) if 'rf_ckpt' in locals() else 0,
        "best_val_acc": float(rf_ckpt["val_acc"]) if 'rf_ckpt' in locals() else 0.0,
        "test_acc": rf_test_acc if 'rf_test_acc' in locals() else 0.0
    },
    "stage2_gan_attribution": {
        "model": "GFD-style Generator+Classifier",
        "classes": GAN_CLASSES,
        "class_to_idx": CLASS_TO_IDX,
        "best_epoch": int(ckpt["epoch"]) if 'ckpt' in locals() else 0,
        "best_val_acc": float(ckpt["val_acc"]) if 'ckpt' in locals() else 0.0,
        "test_acc": test_acc if 'test_acc' in locals() else 0.0,
        "alpha_stamp": ALPHA_STAMP,
        "loss_weights": {
            "adv": LAMBDA_ADV, "perc": LAMBDA_PERC, "res": LAMBDA_RES,
            "hipass": LAMBDA_HIPASS, "cls_residual": LAMBDA_CLS_R, "cls_stamp": LAMBDA_CLS_S
        }
    },
    "training_summary": {
        "total_images_processed": len(df_all) if 'df_all' in locals() else 0,
        "rf_training_epochs": len(rf_metrics_df) if not rf_metrics_df.empty else 0,
        "gan_training_epochs": len(gan_metrics_df) if not gan_metrics_df.empty else 0,
        "models_saved": {
            "real_fake_checkpoint": str(RF_CHECKPOINT),
            "gan_attribution_checkpoint": str(CHECKPOINT)
        }
    }
}

json.dump(final_meta, open(META_JSON, "w"), indent=2)
print(f"üíæ Saved comprehensive metadata ‚Üí {META_JSON}")

print("\n" + "="*60)
print("üéâ INTEGRATED DETECTION PIPELINE COMPLETE!")
print("="*60)
print("‚úÖ Phase 1: Real vs Fake Detection - TRAINED")
print("‚úÖ Phase 2: GAN Attribution - TRAINED")
print("‚úÖ Integrated Pipeline - READY")
print(f"‚úÖ Results saved to: {OUT_CSV}")
print("="*60)